{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Variational Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#myqlm\n",
    "from qat.lang.AQASM import Program, H, RX, RY, RZ, Z, CNOT\n",
    "from qat.lang.AQASM import *\n",
    "from qat.qpus import get_default_qpu\n",
    "from qat.core import Observable, Term\n",
    "from qat.plugins import ScipyMinimizePlugin\n",
    "\n",
    "#imports\n",
    "import ipynb\n",
    "import import_ipynb\n",
    "from vqc_functions import data_embedding, ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing and preprocessing\n",
    "\n",
    "MinMax with feature range from $0$ to $2\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\\\Users\\\\anton.albino\\\\Documents\\\\Anton\\\\codigos\\\\myqlm\\\\qnn\\\\data\\\\iris.data')\n",
    "label = data.iloc[:, -1]\n",
    "features = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.values #returns a numpy array\n",
    "#data normalization (angles from 0 to 2pi)\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 2*np.pi))\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "features = pd.DataFrame(x_scaled)\n",
    "data = features.assign(labels = label)\n",
    "\n",
    "#spliting data\n",
    "training_data, testing_data = train_test_split(data, test_size=0.2, random_state=25)\n",
    "training_features = training_data.iloc[:, :-1]\n",
    "training_labels = training_data.iloc[:, -1]\n",
    "testing_features = testing_data.iloc[:, :-1]\n",
    "testing_labels = testing_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superposition for OneHot and TwoHot encoding\n",
    "\n",
    "Encoding labels into quantum states in superposition in a following basis settings:\n",
    "\n",
    "$\\{|0010\\rangle, |0011\\rangle, |0100\\rangle \\}$ encoding Iris-setosa.\n",
    "\n",
    "\n",
    "\n",
    "$\\{|0101\\rangle, |0110\\rangle, |0111\\rangle \\}$ encoding Iris-versicolor.\n",
    "\n",
    "\n",
    "\n",
    "$\\{|1000\\rangle, |1001\\rangle, |1010\\rangle \\}$ encoding Iris-virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "twohotencoding_training = []\n",
    "for i, iris in enumerate(training_labels):\n",
    "    if iris == \"Iris-setosa\":\n",
    "        twohotencoding_training.append(3)\n",
    "    elif iris == \"Iris-versicolor\":\n",
    "        twohotencoding_training.append(6)\n",
    "    elif iris == \"Iris-virginica\":\n",
    "        twohotencoding_training.append(9)\n",
    "\n",
    "twohotencoding_testing = []\n",
    "for i, iris in enumerate(testing_labels):\n",
    "    if iris == \"Iris-setosa\":\n",
    "        twohotencoding_testing.append(3)\n",
    "    elif iris == \"Iris-versicolor\":\n",
    "        twohotencoding_testing.append(6)\n",
    "    elif iris == \"Iris-virginica\":\n",
    "        twohotencoding_testing.append(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "Loss function used to training the QNN was the mean squared error (MSE) so that the estimator $\\hat{x} = \\hat{p}_{|x\\rangle}$ is compared with label $p_{|x\\rangle} = 1$ since as many as $\\hat{x} \\approx 1$ will minimize the MSE. Therefore, we can write the loss function as\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{N}\\sum_{k=0}^{N}(\\hat{p}_{|x\\rangle} -1)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 7; num_qubits = (features.shape[1]); num_labels = 3\n",
    "\n",
    "def loss(parameters):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        parameters: a np.array for tunable parameters;\n",
    "    Outpu\n",
    "        cost/len(training_data): mean squared error;\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cost=0\n",
    "    for k in range(len(training_features)):\n",
    "        v = training_features.iloc[k,:].to_numpy()\n",
    "\n",
    "        #create program\n",
    "        circuit = Program()\n",
    "        qbits = circuit.qalloc(len(v))\n",
    "\n",
    "        #create subcircuits\n",
    "        encoding = data_embedding(x=v)\n",
    "        variational = ansatz(parameters, feature_len=len(v), num_layers=num_layers)\n",
    "\n",
    "        #adding subcircuits into main circuit\n",
    "        encoding(qbits)\n",
    "        variational(qbits)\n",
    "\n",
    "        qc = circuit.to_circ()\n",
    "        job = qc.to_job()\n",
    "        result = get_default_qpu().submit(job)\n",
    "\n",
    "        meas = {}\n",
    "        for sample in result:\n",
    "            #sample._state returns quantum state in the decimal basis\n",
    "            meas[sample._state] = sample.probability\n",
    "        \n",
    "        estimator_0 = meas[2]+meas[3]+meas[4]\n",
    "        estimator_1 = meas[5]+meas[6]+meas[7]\n",
    "        estimator_2 = meas[8]+meas[9]+meas[10]\n",
    "\n",
    "        #calculating cost\n",
    "        if twohotencoding_training[k] not in meas:\n",
    "            meas[twohotencoding_training[k]]=0\n",
    "        else:\n",
    "            if twohotencoding_training[k]==3:\n",
    "                cost -= np.log10(estimator_0)\n",
    "            elif twohotencoding_training[k]==6:\n",
    "                cost -= np.log10(estimator_1) \n",
    "            elif twohotencoding_training[k]==9:\n",
    "                cost -= np.log10(estimator_2)\n",
    "        \n",
    "    return cost/len(training_features) #Mean squared error / Empirical Risk / Log Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1  \t Loss:  0.514197385646936\n",
      "Iteration:  2  \t Loss:  0.4248225007631388\n",
      "Iteration:  3  \t Loss:  0.3902522463634833\n",
      "Iteration:  4  \t Loss:  0.3442199293864981\n",
      "Iteration:  5  \t Loss:  0.3328687586830843\n",
      "Iteration:  6  \t Loss:  0.3099276763490532\n",
      "Iteration:  7  \t Loss:  0.305379313738272\n",
      "Iteration:  8  \t Loss:  0.2980984931750361\n",
      "Iteration:  9  \t Loss:  0.29401995883457566\n",
      "Iteration:  10  \t Loss:  0.28763974570425466\n",
      "Iteration:  11  \t Loss:  0.28356944468629125\n",
      "Iteration:  12  \t Loss:  0.27719184593854573\n",
      "Iteration:  13  \t Loss:  0.27317440246091007\n",
      "Iteration:  14  \t Loss:  0.26852117297203837\n",
      "Iteration:  15  \t Loss:  0.26659839293568965\n",
      "Iteration:  16  \t Loss:  0.26530309842452354\n",
      "Iteration:  17  \t Loss:  0.2642732719963488\n",
      "Iteration:  18  \t Loss:  0.26341138757524823\n",
      "Iteration:  19  \t Loss:  0.2624999131161802\n",
      "Iteration:  20  \t Loss:  0.26200426963943857\n",
      "Iteration:  21  \t Loss:  0.2613190558201868\n",
      "Iteration:  22  \t Loss:  0.26087114097706343\n",
      "Iteration:  23  \t Loss:  0.26029357092581107\n",
      "Iteration:  24  \t Loss:  0.25979890649858406\n",
      "Iteration:  25  \t Loss:  0.25929347429670624\n",
      "Iteration:  26  \t Loss:  0.25875928637233186\n",
      "Iteration:  27  \t Loss:  0.2578048145548381\n",
      "Iteration:  28  \t Loss:  0.25818050171078477\n",
      "Iteration:  29  \t Loss:  0.2560348498921985\n",
      "Iteration:  30  \t Loss:  0.25471842655509724\n",
      "Iteration:  31  \t Loss:  0.2533164190466205\n",
      "Iteration:  32  \t Loss:  0.25086599931836334\n",
      "Iteration:  33  \t Loss:  0.24837591395653297\n",
      "Iteration:  34  \t Loss:  0.24620809778762281\n",
      "Iteration:  35  \t Loss:  0.2430872610589883\n",
      "Iteration:  36  \t Loss:  0.24113845023237604\n",
      "Iteration:  37  \t Loss:  0.23992531316454668\n",
      "Iteration:  38  \t Loss:  0.2389080567655834\n",
      "Iteration:  39  \t Loss:  0.2381181608127788\n",
      "Iteration:  40  \t Loss:  0.23671870548522467\n",
      "Iteration:  41  \t Loss:  0.23502659709274762\n",
      "Iteration:  42  \t Loss:  0.23390583264465215\n",
      "Iteration:  43  \t Loss:  0.23220807208302838\n",
      "Iteration:  44  \t Loss:  0.23135737258815564\n",
      "Iteration:  45  \t Loss:  0.23058208760842225\n",
      "Iteration:  46  \t Loss:  0.23022479118559075\n",
      "Iteration:  47  \t Loss:  0.22989584690599799\n",
      "Iteration:  48  \t Loss:  0.22962414873818238\n",
      "Iteration:  49  \t Loss:  0.2292995778922775\n",
      "Iteration:  50  \t Loss:  0.2290826815445435\n",
      "Iteration:  51  \t Loss:  0.22898397584263194\n",
      "Iteration:  52  \t Loss:  0.22892845252028293\n",
      "Iteration:  53  \t Loss:  0.22889366815411033\n",
      "Iteration:  54  \t Loss:  0.22887240609649254\n",
      "Iteration:  55  \t Loss:  0.22885494212267338\n",
      "Iteration:  56  \t Loss:  0.22883943387000816\n",
      "Iteration:  57  \t Loss:  0.228826876979064\n",
      "Iteration:  58  \t Loss:  0.22881902704804416\n",
      "Iteration:  59  \t Loss:  0.22881485426914688\n",
      "Iteration:  60  \t Loss:  0.2288128118074654\n",
      "Iteration:  61  \t Loss:  0.22881173870365912\n",
      "Iteration:  62  \t Loss:  0.22881173870365912\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.22881173870365912\n",
      "            Iterations: 62\n",
      "            Function evaluations: 1799\n",
      "            Gradient evaluations: 62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 0.22881173870365912\n",
       "     jac: array([ 2.91205943e-05,  2.65371054e-05,  8.32956284e-05, -7.61654228e-05,\n",
       "        5.80903143e-05,  6.66324049e-05,  7.82702118e-05, -1.28997490e-04,\n",
       "       -2.33862549e-04, -7.42077827e-06, -4.61824238e-05,  1.39184296e-04,\n",
       "        2.74559483e-04,  1.55126676e-04, -4.47090715e-05, -2.07683071e-04,\n",
       "       -3.13110650e-06,  2.19741836e-04, -1.50641426e-04, -6.24731183e-05,\n",
       "       -8.64583999e-05,  8.33310187e-05, -1.50823966e-04,  7.84546137e-06,\n",
       "        6.99069351e-05, -5.79096377e-06,  1.21982768e-04,  8.10790807e-05])\n",
       " message: 'Optimization terminated successfully'\n",
       "    nfev: 1799\n",
       "     nit: 62\n",
       "    njev: 62\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 4.66972324,  5.05245461,  4.86507036,  2.53000282,  0.16344094,\n",
       "        6.3613027 ,  1.08798206,  5.33887251,  6.32473532,  3.67532922,\n",
       "        2.31534234,  4.8069833 ,  3.65228908,  4.87413925,  2.90179019,\n",
       "        4.25077151,  4.63765451,  4.80049247,  3.64947588,  1.88123603,\n",
       "       -0.03766053,  4.28838415,  2.66960012,  1.81689564,  1.25833087,\n",
       "        1.933868  ,  6.08089948,  5.78534779])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "iteration=1\n",
    "convergence = []\n",
    "def callback(variational_parameters):\n",
    "    global iteration\n",
    "    convergence.append(loss(variational_parameters))\n",
    "    print(\"Iteration: \", iteration, \" \\t Loss: \",  loss(variational_parameters))\n",
    "    iteration += 1\n",
    "\n",
    "\n",
    "res = scipy.optimize.minimize(loss, x0=np.random.uniform(0, 2*np.pi, num_layers*num_qubits), \n",
    "                                method = 'SLSQP', callback=callback,\n",
    "                                options={'maxiter': 200, 'ftol': 1e-06, 'iprint': 1, 'disp': True, \n",
    "                                'eps': 1.4901161193847656e-08, 'finite_diff_rel_step': None})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0 \t Inference:  True\n",
      "Sample: 1 \t Inference:  True\n",
      "Sample: 2 \t Inference:  True\n",
      "Sample: 3 \t Inference:  True\n",
      "Sample: 4 \t Inference:  True\n",
      "Sample: 5 \t Inference:  True\n",
      "Sample: 6 \t Inference:  True\n",
      "Sample: 7 \t Inference:  True\n",
      "Sample: 8 \t Inference:  False  - Misclassified\n",
      "Sample: 9 \t Inference:  True\n",
      "Sample: 10 \t Inference:  True\n",
      "Sample: 11 \t Inference:  True\n",
      "Sample: 12 \t Inference:  True\n",
      "Sample: 13 \t Inference:  True\n",
      "Sample: 14 \t Inference:  True\n",
      "Sample: 15 \t Inference:  True\n",
      "Sample: 16 \t Inference:  True\n",
      "Sample: 17 \t Inference:  True\n",
      "Sample: 18 \t Inference:  True\n",
      "Sample: 19 \t Inference:  True\n",
      "Sample: 20 \t Inference:  True\n",
      "Sample: 21 \t Inference:  True\n",
      "Sample: 22 \t Inference:  True\n",
      "Sample: 23 \t Inference:  True\n",
      "Sample: 24 \t Inference:  True\n",
      "Sample: 25 \t Inference:  True\n",
      "Sample: 26 \t Inference:  True\n",
      "Sample: 27 \t Inference:  True\n",
      "Sample: 28 \t Inference:  True\n",
      "Sample: 29 \t Inference:  True\n",
      "\n",
      " \n",
      " \n",
      " Accuracy:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "def testing():\n",
    "    trues = []\n",
    "    for i, y_data in enumerate(testing_labels):\n",
    "\n",
    "        circuit = Program()\n",
    "        v = testing_features.iloc[i].to_numpy()\n",
    "        qbits = circuit.qalloc(len(v))\n",
    "\n",
    "        #create subcircuits\n",
    "        encoding = data_embedding(x=v)\n",
    "        #trained ansatz\n",
    "        variational = ansatz(res['x'], feature_len=len(v), num_layers=num_layers)\n",
    "\n",
    "        #adding subcircuits into main circuit\n",
    "        encoding(qbits)\n",
    "        variational(qbits)\n",
    "        \n",
    "        qc = circuit.to_circ()\n",
    "        job = qc.to_job()\n",
    "        result = get_default_qpu().submit(job)\n",
    "\n",
    "        meas = {}\n",
    "        for sample in result:\n",
    "            meas[sample._state] = sample.probability\n",
    "\n",
    "        #testing\n",
    "        estimator_0 = meas[2]+meas[3]+meas[4]\n",
    "        estimator_1 = meas[5]+meas[6]+meas[7]\n",
    "        estimator_2 = meas[8]+meas[9]+meas[10]\n",
    "\n",
    "        irislabels = [estimator_0, estimator_1, estimator_2]\n",
    "\n",
    "\n",
    "        if (twohotencoding_testing[i]==3 and estimator_0 > estimator_1 and estimator_0 > estimator_2):\n",
    "            trues.append(1)\n",
    "            print(f\"Sample: {i} \\t Inference: \", True)\n",
    "        elif (twohotencoding_testing[i]==6 and estimator_1 > estimator_0 and estimator_1 > estimator_2):\n",
    "            trues.append(1)\n",
    "            print(f\"Sample: {i} \\t Inference: \", True)\n",
    "        elif (twohotencoding_testing[i]==9 and estimator_2 > estimator_0 and estimator_2 > estimator_1):\n",
    "            trues.append(1)\n",
    "            print(f\"Sample: {i} \\t Inference: \", True)\n",
    "        else:\n",
    "            print(f\"Sample: {i} \\t Inference: \", False, \" - Misclassified\")\n",
    "\n",
    "    return trues\n",
    "\n",
    "\n",
    "print('\\n \\n \\n Accuracy: ', len(testing())/len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(convergence)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss value\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A total of 30 testing samples were used and 28 were classified correctly.\n"
     ]
    }
   ],
   "source": [
    "print(f\" A total of {testing_data.shape[0]} testing samples were used and {len(testing())} were classified correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "445da9f97fff3e9607fce724e9f5124fca1a39a333bfa2bf5db6a7377ace2fc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
